{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://github.com/jocicmarko/ultrasound-nerve-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('th')\n",
    "img_rows = 128\n",
    "img_cols = 160\n",
    "image_rows = 420\n",
    "image_cols = 580\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    inputs = Input((1, img_rows, img_cols))\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size = (2, 2))(conv5)\n",
    "    \n",
    "    conv5_5 = Convolution2D(1024, 3, 3, activation = 'relu', border_mode = 'same')(pool5)\n",
    "    conv5_5 = Convolution2D(512, 3, 3, activation = 'relu', border_mode = 'same')(conv5_5)\n",
    "    \n",
    "    up5_5 = merge([UpSampling2D(size = (2, 2))(conv5_5), conv5],mode = 'concat', concat_axis =1)\n",
    "    conv6_5 = Convolution2D(512, 3, 3, activation = 'relu', border_mode = 'same')(up5_5)\n",
    "    conv6_5 = Convolution2D(256, 3, 3, activation = 'relu', border_mode = 'same')(conv6_5)\n",
    "    \n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv6_5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], imgs.shape[1], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i, 0] = cv2.resize(imgs[i, 0], (img_cols, img_rows), interpolation=cv2.INTER_CUBIC)\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict():\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=16, nb_epoch=20, verbose=1, shuffle=True,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('unet.hdf5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('finish...')\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    img = img.astype('float32')\n",
    "    img = cv2.threshold(img, 0.5, 1., cv2.THRESH_BINARY)[1].astype(np.uint8)\n",
    "    img = cv2.resize(img, (image_cols, image_rows))\n",
    "    return img\n",
    "\n",
    "\n",
    "def run_length_enc(label):\n",
    "    from itertools import chain\n",
    "    x = label.transpose().flatten()\n",
    "    y = np.where(x > 0)[0]\n",
    "    if len(y) < 10:  # consider as empty\n",
    "        return ''\n",
    "    z = np.where(np.diff(y) > 1)[0]\n",
    "    start = np.insert(y[z+1], 0, y[0])\n",
    "    end = np.append(y[z], y[-1])\n",
    "    length = end - start\n",
    "    res = [[s+1, l+1] for s, l in zip(list(start), list(length))]\n",
    "    res = list(chain.from_iterable(res))\n",
    "    return ' '.join([str(r) for r in res])\n",
    "\n",
    "\n",
    "def submission():\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = np.load('imgs_mask_test.npy')\n",
    "\n",
    "    argsort = np.argsort(imgs_id_test)\n",
    "    imgs_id_test = imgs_id_test[argsort]\n",
    "    imgs_test = imgs_test[argsort]\n",
    "\n",
    "    total = imgs_test.shape[0]\n",
    "    ids = []\n",
    "    rles = []\n",
    "    for i in range(total):\n",
    "        img = imgs_test[i, 0]\n",
    "        img = prep(img)\n",
    "        rle = run_length_enc(img)\n",
    "\n",
    "        rles.append(rle)\n",
    "        ids.append(imgs_id_test[i])\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print('{}/{}'.format(i, total))\n",
    "\n",
    "    first_row = 'img,pixels'\n",
    "    file_name = 'submission3.csv'\n",
    "\n",
    "    with open(file_name, 'w+') as f:\n",
    "        f.write(first_row + '\\n')\n",
    "        for i in range(total):\n",
    "            s = str(ids[i]) + ',' + rles[i]\n",
    "            f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_train, imgs_mask_train = load_train_data()\n",
    "imgs_test, imgs_id = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 252s - loss: 0.1320   \n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0413   \n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0346   \n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 245s - loss: 0.0302   \n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 245s - loss: 0.0278   \n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 245s - loss: 0.0266   \n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 245s - loss: 0.0251   \n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 245s - loss: 0.0239   \n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 245s - loss: 0.0229   \n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0221   \n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0213   \n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0206   \n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0198   \n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0190   \n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0178   \n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0170   \n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0162   \n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0153   \n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0146   \n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 246s - loss: 0.0137   \n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "5508/5508 [==============================] - 75s    \n",
      "------------------------------\n",
      "finish...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5508\n",
      "1000/5508\n",
      "2000/5508\n",
      "3000/5508\n",
      "4000/5508\n",
      "5000/5508\n"
     ]
    }
   ],
   "source": [
    "submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### result 0.59124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
